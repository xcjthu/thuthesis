\chapter{实验结果}
\label{cha:result}

我们针对性的在案由/罪名预测、相关法条预测、刑期预测、关键词抽取任务上，开展了多个不同的实验。实验结果表明，我们提出的模型超过了以往对应的模型，实现了state-of-the-art的效果。

\section{判决预测模块}
\subsection{实验设置}

针对于判决预测模块提出的多任务学习模型，我们在多个相关数据集上进行了相应的实验。我们根据北大法宝、中国裁判文书网、中国司法挑战赛三个数据来源，构建了相应的三个判决预测数据集。对所有文本，利用了THULAC工具进行分词，统一利用FastText训练了200维的词向量。利用规则、人工标注，从各个文书的判决结果中，抽取出了每一篇文书相应的罪名、法条、刑期等标注信息，并进行了人工检错，并将数据集随机按照8:2的比例划分成了训练集与测试集。我们采用了以下文本分类模型做baseline：
\begin{itemize}
	\item TFIDF+SVM：这是文本分类最常用的传统分类算法，我们应用了词频与逆文档频率TFIDF抽取文档特征，并以此为基础采用了支持向量机SVM进行分类。
	\item CNN：我们采用了卷积神经网络[14]作为编码器，让机器在阅读文章后自动抽取出对分类有用的特征，再将其映射到各个罪名、法条、刑期上。为了对比，我们在改编码器上运用了基本的多任务学习机制，来与我们的模型进行对比。
	\item Fact-Law：[15]是由北大团队自然语言处理团队在2017年提出的罪名预测模型。模型通过引入法条描述，利用Attention机制来提升模型预测罪名的效果。
	\item Pipeline：这是一个基本的多任务学习的模型，该模型为不同的子任务训练不同的编码器，通过在输出层融合不同任务的信息，捕获任务之间的依赖关系。
\end{itemize}

\begin{table}[]
\begin{tabular}{l|llll|llll|llll}
\hline
任务        & \multicolumn{4}{l|}{相关法条推荐} & \multicolumn{4}{l|}{案由/罪名预测} & \multicolumn{4}{l}{刑期预测} \\ \hline
评价指标      & Acc   & MP    & MR   & F1   & Acc   & MP    & MR   & F1   & Acc  & MP   & MR   & F1   \\ \hline
TFIDF+SVM & 82.4  & 45.5  & 26.7 & 30.2 & 82.2  & 47.4  & 27.9 & 31.3 & 48.5 & 36   & 16.7 & 16.5 \\
CNN       & 92.5  & 46.9  & 38.4 & 40.0 & 92.3  & 41.2  & 32.3 & 33.7 & 57.4 & 35.6 & 22.2 & 22.7 \\
Fact-law  & 93.5  & 50.9  & 45.6 & 45.9 & 93.4  & 47.2  & 41.4 & 41.5 & 56.3 & 31.3 & 26.4 & 26.7 \\
Pipeline  & 93.7  & 51.9  & 44.1 & 44.9 & 93.6  & 45.5  & 39.1 & 39.3 & 58.2 & 38.2 & 24.9 & 26.8 \\ \hline
\textbf{Ours}      & \textbf{94.4}  & \textbf{53.9}  & \textbf{47.3} & \textbf{48.2} & \textbf{94.9}  & \textbf{53.9}  & \textbf{48.2} & \textbf{49.1} & \textbf{58.5} & \textbf{40.2} & \textbf{32.9} & \textbf{32.8} \\ \hline
\end{tabular}
\caption{模型在裁判文书网数据集上效果}
\label{table: result_judge_cjo}
\end{table}


\begin{table}[]
\begin{tabular}{l|llll|llll|llll}
\hline
任务        & \multicolumn{4}{l|}{相关法条推荐} & \multicolumn{4}{l|}{案由/罪名预测} & \multicolumn{4}{l}{刑期预测} \\
\hline
评价指标      & Acc    & MP   & MR   & F1   & Acc     & MP   & MR   & F1   & Acc  & MP   & MR   & F1   \\ \hline
TFIDF+SVM & 80.9   & 51.3 & 32.6 & 36.4 & 81.0    & 53.4 & 35.4 & 38.7 & 45.3 & 30.4 & 17.4 & 17.2 \\
CNN       & 93.1   & 64.3 & 52.6 & 54.3 & 93.3    & 61.9 & 49.3 & 51.1 & 57.6 & 24.1 & 23.1 & 23.3 \\
Fact-law  & 93.9   & 68.1 & 63.4 & 63.5 & 94.2    & 65.8 & 58.5 & 58.7 & 55.7 & 27.7 & 27.4 & 26.5 \\
Pipeline  & 94.4   & 69.6 & 61.0 & 62.2 & 94.3    & 65.1 & 56.2 & 57.2 & \textbf{58.2} & 36.2 & 26.4 & 27.1 \\ \hline
Ours      & \textbf{95.4}   & \textbf{76.4} & \textbf{67.6} & \textbf{68.4} & \textbf{95.6}    & \textbf{75.9} & \textbf{69.6} & \textbf{70.9} & 57.8 & \textbf{38.9} & \textbf{32.1} & \textbf{31.8} \\ \hline
\end{tabular}
\caption{模型在北大法宝数据集上的效果}
\label{table: result_judge_pku}
\end{table}

\subsection{实验结果与分析}
由表中数据可知，我们的模型在相关法条推荐、案由/罪名预测、刑期预测三个任务上超过了之前的baseline，取得了很好的效果。多个数据集上的实验体现了我们提出模型的鲁棒性与有效性。

\begin{table}[]
\begin{tabular}{l|llll|llll|llll}
\hline
任务        & \multicolumn{4}{l}{相关法条推荐} & \multicolumn{4}{l|}{案由/罪名预测} & \multicolumn{4}{l}{刑期预测}  \\
\hline
评价指标      & Acc   & MP   & MR   & F1   & Acc   & MP    & MR   & F1   & Acc  & MP   & MR   & F1   \\ \hline
TFIDF+SVM & 60.1  & 54.9 & 45.3 & 46.3 & 59.2  & 53.9  & 45.0 & 45.7 & 28.4 & 22.9 & 20.0 & 18.1 \\
CNN       & 81.4  & 74.4 & 64.1 & 65.7 & 80.7  & 77.3  & 65.5 & 67.2 & 28.8 & 34.7 & 27.8 & 28.6 \\
Fact-law  & 70.9  & 64.8 & 63.6 & 59.1 & 68.7  & 66.1  & 65.3 & 60.1 & 36.5 & 29.9 & 27.6 & 27.1 \\
Pipeline  & 84.7  & 80.7 & 68.6 & 70.8 & 83.6  & 81.6  & 70.0 & 72.1 & \textbf{40.0}   & \textbf{37.4} & 32.0 & 31.6 \\ \hline
Ours      & \textbf{86.3}  & \textbf{81.9} & \textbf{71.1} & \textbf{73.4} & \textbf{85.7}  & \textbf{83.4}  & \textbf{76.0}   & \textbf{78.3} & 38.3 & 36.1 & \textbf{33.1} & \textbf{32.1} \\ \hline
\end{tabular}
\caption{模型在CAIL数据集上效果}
\label{table: result_judge_cail}
\end{table}

同时，由于考虑了多个任务之间的相互依赖关系，我们的模型解决了预测结果互相矛盾的问题。例如模型在相关法条预测结果为涉及“盗窃罪”的法条，而在案由/罪名预测时却将被告判断为“故意杀人罪”，这样的预测结果矛盾现象在其他模型中非常常见。我们的模型很好的解决了这样一个问题，因此实现了优越的效果。


\section{关键词抽取模块}
\subsection{实验设置}

针对于关键词预测模块，我们统一使用我们构造的人工标注的数据集作为benchmark进行评测。我们利用了以下传统的关键词抽取模型作为模型baseline进行对比。

\begin{itemize}
	\item CRF：条件随机场是一个传统的基于概率统计的序列标注模型。第一步人工抽取特征，模型通过学习基于这些特征的关键词概率分布来进行训练。
	\item BiLSTM+CRF：双向LSTM与CRF的结合，是目前神经网络运用于序列标注的最主要的模型。利用神经网络抽取特征的能力，来避免人工抽取特征的不全面与高代价。
\end{itemize}

\subsection{实验结果与分析}

从实验结果可见，我们的模型在关键词提取任务上实现了大幅的提升。相比于传统的字级别的序列标注模型与词级别的序列标注模型，我们使用的模型综合了字级别的信息与词级别的信息，以此避免了词级别模型过度依赖分词效果与字级别模型无法捕捉到足够信息的缺点。

\begin{table}[]
\center
\begin{tabular}{llll}
\hline
       & Precision  & Recall & F1    \\ \hline
CRF        & 58.16  & 41.61 & 48.51 \\
BiLSTM-CRF & 62.45  & 61.46 & 63.47 \\ \hline
Ours       & \textbf{68.14}  & \textbf{67.83} & \textbf{67.99} \\ \hline
\end{tabular}
\caption{关键词抽取算法效果}
\end{table}

